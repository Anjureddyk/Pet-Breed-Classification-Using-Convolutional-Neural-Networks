{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4609a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3544df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset directory\n",
    "dataset_dir = 'C:/Users/Anju Reddy K/Personal_projects/pet breed classification/Pet_Breeds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6014664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image size for resizing\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8f323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3105 images belonging to 23 classes.\n",
      "Found 776 images belonging to 23 classes.\n",
      "{'abyssinian': 0, 'american shorthair': 1, 'beagle': 2, 'boxer': 3, 'bulldog': 4, 'chihuahua': 5, 'corgi': 6, 'dachshund': 7, 'german shepherd': 8, 'golden retriever': 9, 'husky': 10, 'labrador': 11, 'maine coon': 12, 'mumbai cat': 13, 'persian cat': 14, 'pomeranian': 15, 'pug': 16, 'ragdoll cat': 17, 'rottwiler': 18, 'shiba inu': 19, 'siamese cat': 20, 'sphynx': 21, 'yorkshire terrier': 22}\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values between 0 and 1\n",
    "    validation_split=0.2  # Split the dataset into training and validation sets\n",
    ")\n",
    "\n",
    "# Load the dataset and split it into training and validation sets\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Use a subset of the data for training\n",
    ")\n",
    "\n",
    "validation_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Use a subset of the data for validation\n",
    ")\n",
    "\n",
    "# Print the class labels\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19ec32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5571eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813aba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # num_classes is the number of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ae5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c0cbe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 413s 4s/step - loss: 3.2463 - accuracy: 0.0534 - val_loss: 3.0403 - val_accuracy: 0.0703\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 450s 5s/step - loss: 2.9103 - accuracy: 0.1357 - val_loss: 2.8910 - val_accuracy: 0.1745\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 417s 4s/step - loss: 2.4411 - accuracy: 0.2860 - val_loss: 3.0206 - val_accuracy: 0.1667\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 377s 4s/step - loss: 1.6470 - accuracy: 0.5265 - val_loss: 3.9124 - val_accuracy: 0.1380\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 361s 4s/step - loss: 0.7687 - accuracy: 0.7846 - val_loss: 5.5388 - val_accuracy: 0.1406\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=validation_data.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181a4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 51s 2s/step - loss: 5.5316 - accuracy: 0.1392\n",
      "Validation Loss: 5.5316\n",
      "Validation Accuracy: 13.92%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "test_loss, test_accuracy = model.evaluate(validation_data)\n",
    "print(f\"Validation Loss: {test_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c181ff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 196s 2s/step - loss: 0.3521 - accuracy: 0.9333\n",
      "Validation Loss: 0.3521\n",
      "Validation Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "test_loss, test_accuracy = model.evaluate(train_data)\n",
    "print(f\"Validation Loss: {test_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676b76b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 452ms/step\n",
      "Predicted Breed: beagle\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Set the path to the uploaded image\n",
    "image_path = 'dog.jpg'\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=image_size)\n",
    "img = image.img_to_array(img)\n",
    "img = img / 255.0  # Normalize pixel values\n",
    "img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img)\n",
    "predicted_label = np.argmax(predictions[0])\n",
    "\n",
    "# Get the breed name from the class labels\n",
    "class_labels = ['abyssinian', 'american shorthair', 'beagle', 'boxer', 'bulldog', 'chihuahua', 'corgi', 'dachshund', 'german shepherd', 'golden retriever', 'husky', 'labrador', 'maine coon', 'mumbai cat', 'persian cat', 'pomeranian', 'pug', 'ragdoll cat', 'rottwiler', 'shiba inu', 'siamese cat', 'sphynx', 'yorkshire terrier']  # Replace with your class labels\n",
    "predicted_breed = class_labels[predicted_label]\n",
    "\n",
    "# Print the predicted breed name\n",
    "print(f\"Predicted Breed: {predicted_breed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98386ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425a53c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14917e6a167d46d28edac387b3f00c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59874214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
